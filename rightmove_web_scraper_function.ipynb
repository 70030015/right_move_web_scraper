{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from lxml import html, etree\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the function is to extract data from the listings on the http://www.rightmove.co.uk/ property website. After passing the function the long url from the first results page of a search, the function will extract the price, property type, address details, and url for the specific property listing. It will also extract the postcode stems from the address details (e.g. 'N1') and store this in a separate column; and extract the number of bedrooms from the property type as a separate column. If more than one page of results are returned by the search then the function will automatically cycle through all pages collecting the data (which means it can take a while to return the results if the search criteria returns thousands of results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rightmove_webscrape(rightmove_url,rent_or_buy):\n",
    "    \n",
    "# Get the start & end of the web url around the index value\n",
    "    start,end = rightmove_url.split('&index=')\n",
    "    url_start = start+'&index='\n",
    "    url_end = end[1:]\n",
    "    \n",
    "# Initialise variables\n",
    "    price_pcm=[]\n",
    "    titles=[]\n",
    "    addresses=[]\n",
    "    weblinks=[]\n",
    "    page_counts=[]\n",
    "    \n",
    "# Initialise pandas DataFrame for results.\n",
    "    df=pd.DataFrame(columns=['price','type','address','url'])\n",
    "\n",
    "# Get the total number of results from the search\n",
    "    page = requests.get(rightmove_url)\n",
    "    tree = html.fromstring(page.content)\n",
    "    xp_result_count = '//span[@class=\"searchHeader-resultCount\"]/text()'\n",
    "    result_count = int(tree.xpath(xp_result_count)[0].replace(\",\", \"\"))\n",
    "    \n",
    "# Turn the total number of search results into number of iterations for the loop\n",
    "    loop_count = result_count/24\n",
    "    if result_count%24>0:\n",
    "        loop_count = loop_count+1\n",
    "        \n",
    "# Set the Xpath variables for the loop\n",
    "    if rent_or_buy=='rent':\n",
    "        xp_prices = '//span[@class=\"propertyCard-priceValue\"]/text()'\n",
    "    elif rent_or_buy=='buy':\n",
    "        xp_prices = '//div[@class=\"propertyCard-priceValue\"]/text()'\n",
    "        \n",
    "    xp_titles = '//div[@class=\"propertyCard-details\"]//a[@class=\"propertyCard-link\"]//h2[@class=\"propertyCard-title\"]/text()'\n",
    "    xp_addresses = '//address[@class=\"propertyCard-address\"]/text()'\n",
    "    xp_weblinks = '//div[@class=\"propertyCard-details\"]//a[@class=\"propertyCard-link\"]/@href'\n",
    "\n",
    "# Start the loop through the search result web pages\n",
    "    for pages in range(0,loop_count,1):\n",
    "        rightmove_url = url_start+str(pages*24)+url_end\n",
    "        page = requests.get(rightmove_url)\n",
    "        tree = html.fromstring(page.content)\n",
    "        \n",
    "# Reset variables\n",
    "        price_pcm=[]\n",
    "        titles=[]\n",
    "        addresses=[]\n",
    "        weblinks=[]\n",
    "\n",
    "# Create data lists from Xpaths\n",
    "        for val in tree.xpath(xp_prices):\n",
    "            price_pcm.append(val)\n",
    "        for val in tree.xpath(xp_titles):\n",
    "            titles.append(val)\n",
    "        for val in tree.xpath(xp_addresses):\n",
    "            addresses.append(val)\n",
    "        for val in tree.xpath(xp_weblinks):\n",
    "            weblinks.append(val)\n",
    "\n",
    "# Convert data to temporary DataFrame\n",
    "        data = [price_pcm, titles, addresses, weblinks]\n",
    "        temp_df= pd.DataFrame(data)\n",
    "        temp_df = temp_df.transpose()\n",
    "        temp_df.columns=['price','type','address','url']\n",
    "        \n",
    "# Drop empty rows from DataFrame which come from placeoholders in html file.\n",
    "        temp_df = temp_df[temp_df.url != '/property-for-sale/property-0.html']\n",
    "    \n",
    "# Join temporary DataFrame to main results DataFrame.\n",
    "        frames = [df,temp_df]\n",
    "        df = pd.concat(frames)\n",
    "\n",
    "# Renumber results DataFrame index to remove duplicate index values.\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "# Convert price column to numeric values for analysis.\n",
    "    df.price.replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "    df.price=pd.to_numeric(df.price)\n",
    "\n",
    "# Extract postcode areas to separate column.\n",
    "    df['postcode'] = df['address'].str.extract(r'\\b([A-Za-z][A-Za-z]?[0-9][0-9]?[A-Za-z]?)\\b',expand=True)\n",
    "    \n",
    "# Extract number of bedrooms from 'type' column.\n",
    "    df['number_bedrooms'] = df.type.str.extract(r'\\b([\\d][\\d]?)\\b',expand=True)\n",
    "    df.loc[df['type'].str.contains('studio',case=False),'number_bedrooms']=0\n",
    "\n",
    "# Add in search_date column with date website was queried (i.e. today's date).\n",
    "    now = dt.datetime.today().strftime(\"%d/%m/%Y\")\n",
    "    df['search_date'] = now\n",
    "\n",
    "# Optional line to export the results to CSV if you wish to inspect them in an alternative program.\n",
    "#     df.to_csv('rightmove_df.csv',encoding='utf-8')\n",
    "\n",
    "    print 'The search returned a total of ', len(df),' results.'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the function you first need to go to http://www.rightmove.co.uk/ and perform your search based on your desired criteria (e.g. 1 bedroom flats to rent in London Fields added to the website in the last 7 days). When the first page of results comes up copy the long url from the browser window and set it as the *url* variable (in this example the search is for all residential properties for sale in London fields).\n",
    "\n",
    "The second argument to pass to the function is just a text value of 'buy' or 'rent' depending on what you searched for on rightmove. This argument ensures that the correct Xpaths are used in the function to produce the price values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rent_url = 'http://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=REGION%5E70417&numberOfPropertiesPerPage=24&radius=0.0&sortType=6&index=0&propertyTypes=detached%2Csemi-detached%2Cterraced%2Cflat%2Cbungalow&includeLetAgreed=false&viewType=LIST&areaSizeUnit=sqft&currencyCode=GBP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buy_url = 'http://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=REGION%5E70417&numberOfPropertiesPerPage=24&radius=0.0&sortType=2&index=0&includeSSTC=false&viewType=LIST&areaSizeUnit=sqft&currencyCode=GBP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply run the function on the url variable to create the dataframe. Here we'll assign the results to the *df* variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The search returned a total of  154  results.\n"
     ]
    }
   ],
   "source": [
    "url = buy_url\n",
    "df = rightmove_webscrape(url,'buy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the first few rows of data to check that the function worked as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>type</th>\n",
       "      <th>address</th>\n",
       "      <th>url</th>\n",
       "      <th>postcode</th>\n",
       "      <th>number_bedrooms</th>\n",
       "      <th>search_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>2 bedroom flat for sale</td>\n",
       "      <td>Pritchards Road, London</td>\n",
       "      <td>/property-for-sale/property-61788488.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>16/09/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2350000.0</td>\n",
       "      <td>4 bedroom terraced house for sale</td>\n",
       "      <td>Albion Square, Hackney, E8</td>\n",
       "      <td>/property-for-sale/property-61569422.html</td>\n",
       "      <td>E8</td>\n",
       "      <td>4</td>\n",
       "      <td>16/09/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2100000.0</td>\n",
       "      <td>4 bedroom terraced house for sale</td>\n",
       "      <td>Elrington Road, Hackney</td>\n",
       "      <td>/property-for-sale/property-56114773.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>16/09/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Detached house for sale</td>\n",
       "      <td>76 Shrubland Road, London, Hackney, E8 4NH</td>\n",
       "      <td>/property-for-sale/property-61276148.html</td>\n",
       "      <td>E8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/09/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000000.0</td>\n",
       "      <td>4 bedroom semi-detached house for sale</td>\n",
       "      <td>Greenwood Road, London Fields, Hackney, London...</td>\n",
       "      <td>/property-for-sale/property-43998885.html</td>\n",
       "      <td>E8</td>\n",
       "      <td>4</td>\n",
       "      <td>16/09/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price                                    type  \\\n",
       "0   550000.0                 2 bedroom flat for sale   \n",
       "1  2350000.0       4 bedroom terraced house for sale   \n",
       "2  2100000.0       4 bedroom terraced house for sale   \n",
       "3  2000000.0                 Detached house for sale   \n",
       "4  2000000.0  4 bedroom semi-detached house for sale   \n",
       "\n",
       "                                             address  \\\n",
       "0                            Pritchards Road, London   \n",
       "1                         Albion Square, Hackney, E8   \n",
       "2                            Elrington Road, Hackney   \n",
       "3         76 Shrubland Road, London, Hackney, E8 4NH   \n",
       "4  Greenwood Road, London Fields, Hackney, London...   \n",
       "\n",
       "                                         url postcode number_bedrooms  \\\n",
       "0  /property-for-sale/property-61788488.html      NaN               2   \n",
       "1  /property-for-sale/property-61569422.html       E8               4   \n",
       "2  /property-for-sale/property-56114773.html      NaN               4   \n",
       "3  /property-for-sale/property-61276148.html       E8             NaN   \n",
       "4  /property-for-sale/property-43998885.html       E8               4   \n",
       "\n",
       "  search_date  \n",
       "0  16/09/2016  \n",
       "1  16/09/2016  \n",
       "2  16/09/2016  \n",
       "3  16/09/2016  \n",
       "4  16/09/2016  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And export the full results to *csv* for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('search_results.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional html export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the event that the search does not return results as expected it may be that the Xpaths have changed and need updating; alternatively you may wish to add in additional Xpaths to collect more data. The below will export the full html text file from whichever url you set as the variable *rightmove_url*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get(rightmove_url)\n",
    "tree = html.fromstring(page.content)\n",
    "html_text=etree.tostring(tree)\n",
    "file = open(\"html.txt\", \"w\")\n",
    "file.write(html_text)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
